{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629720be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# draw landmarks & connections to screen\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# import Pose model\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "530cac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_angle(x, y, z):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    z = np.array(z)\n",
    "\n",
    "    radians = np.arctan2(z[1]-y[1], z[0]-y[0]) - np.arctan2(x[1]-y[1], x[0]-y[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ece6210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognise_curl(detection):\n",
    "    \n",
    "    global counter\n",
    "    global state\n",
    "    global feedback\n",
    "    global range_flag\n",
    "    global left_angle\n",
    "    global right_angle\n",
    "    \n",
    "    try:\n",
    "        landmarks = detection.pose_landmarks.landmark\n",
    "        \n",
    "        # left arm\n",
    "        left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "        left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "        left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y] \n",
    "\n",
    "        # right arm\n",
    "        right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "        right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "        right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "        \n",
    "        left_elbow_angle = calc_angle(left_shoulder, left_elbow, left_wrist)\n",
    "        right_elbow_angle = calc_angle(right_shoulder, right_elbow, right_wrist)\n",
    "        left_angle.append(int(left_elbow_angle))\n",
    "        right_angle.append(int(right_elbow_angle))\n",
    "        \n",
    "        # down state\n",
    "        if left_elbow_angle > 160 and right_elbow_angle > 160:\n",
    "            if not range_flag:\n",
    "                feedback = 'Did not curl completely.'\n",
    "            else:\n",
    "                feedback = 'Good rep!'\n",
    "            state = 'Down'\n",
    "            \n",
    "        # not fully curled\n",
    "        elif (left_elbow_angle > 50 and right_elbow_angle > 50) and state == 'Down':\n",
    "            range_flag = False\n",
    "            feedback = ''\n",
    "            \n",
    "        # up state\n",
    "        elif (left_elbow_angle < 30 and right_elbow_angle < 30) and state == 'Down':\n",
    "            state = 'Up'\n",
    "            feedback = ''\n",
    "            range_flag = True\n",
    "            counter += 1\n",
    "    \n",
    "    except:\n",
    "        left_angle.append(180)\n",
    "        right_angle.append(180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "003c5f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognise_squat(detection):\n",
    "    \n",
    "    global counter\n",
    "    global state\n",
    "    global feedback\n",
    "    global left_angle\n",
    "    global right_angle\n",
    "       \n",
    "    try:\n",
    "        landmarks = detection.pose_landmarks.landmark\n",
    "        \n",
    "        # GET COORDINATES\n",
    "        left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "        left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "        left_heel = [landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y]\n",
    "        \n",
    "        right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "        right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "        right_heel = [landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].y]\n",
    "        \n",
    "        left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "        right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "\n",
    "        left = calc_angle(left_hip, left_knee, left_heel)\n",
    "        right = calc_angle(right_hip, right_knee, right_heel)        \n",
    "        left_angle.append(int(left))\n",
    "        right_angle.append(int(right))\n",
    "        \n",
    "        #POSE CHECKING 1: Knees bending inwards    \n",
    "        shoulder_dist = left_shoulder[0] - right_shoulder[0]\n",
    "        knee_dist = left_knee[0] - right_knee[0]\n",
    "\n",
    "        if shoulder_dist - knee_dist > 0.04:\n",
    "            feedback = 'Open up your knees further apart to shoulder width!'\n",
    "        else:\n",
    "            feedback = ''\n",
    "\n",
    "        # standing up\n",
    "        if left > 170 and right > 170:\n",
    "            state = \"Up\"\n",
    "            \n",
    "        if left < 165 and right < 165:\n",
    "            feedback = 'Almost there... lower until height of hips!'\n",
    "            \n",
    "        if left < 140 and right < 140 and state == \"Up\":\n",
    "            state = \"Down\"\n",
    "            counter += 1\n",
    "            \n",
    "        if state == \"Down\":\n",
    "            feedback = 'Good rep!'\n",
    "    \n",
    "    except:\n",
    "        left_angle.append(180)\n",
    "        right_angle.append(180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8b4ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognise_situp(detection):\n",
    "    \n",
    "    global counter\n",
    "    global state\n",
    "    global feedback\n",
    "    global range_flag\n",
    "    global halfway\n",
    "    global body_angles\n",
    "    \n",
    "    try: \n",
    "        landmarks = detection.pose_landmarks.landmark\n",
    "        \n",
    "        left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "        left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "        left_heel = [landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y]\n",
    "        left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "\n",
    "        # CALCULATE ANGLES \n",
    "        angle_knee = calc_angle(left_hip, left_knee, left_heel)\n",
    "        angle_body = calc_angle(left_shoulder, left_hip, left_knee)\n",
    "        body_angles.append(int(angle_body))\n",
    "      \n",
    "        if (angle_body < 80 and angle_body > 50) and state == \"Down\": #Half-way there (Used for checking bad situps)\n",
    "            halfway = True\n",
    "\n",
    "        if angle_body < 40 and state == \"Down\": #Complete situp\n",
    "            state = \"Up\"\n",
    "            range_flag = True\n",
    "            \n",
    "        if angle_body > 90 and angle_knee < 60: #Resting position;to check if situp was done properly\n",
    "            state = \"Down\"\n",
    "            \n",
    "            if halfway: #Check if a rep was attempted\n",
    "                if range_flag: #Check if a proper rep was performed\n",
    "                    counter += 1\n",
    "                    feedback = \"Good repetition!\"\n",
    "                else:\n",
    "                    feedback = \"Did not perform sit up completely.\"\n",
    "                range_flag = False #Reset vars\n",
    "                halfway = False\n",
    "                \n",
    "        if angle_knee > 70: #Triggers anytime the legs are not tucked in\n",
    "            feedback = \"Keep legs tucked in closer\"\n",
    "\n",
    "    except: \n",
    "        body_angles.append(180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1639f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_viz(user_choice):\n",
    "    \n",
    "    # Set figure size\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "    \n",
    "    # Squat viz\n",
    "    if user_choice == 1:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(frames, left_angle, '-', color = 'red', label = 'Left Knee Angle')\n",
    "        ax.plot(frames, right_angle, '-', color = 'blue', label = 'Right Knee Angle')\n",
    "        ax.axhline(y=140, color='g', linestyle='--')\n",
    "        ax.legend(loc = 'center left')\n",
    "        ax.set_xlabel('Frames')\n",
    "        ax.set_ylabel('Angle')\n",
    "        print(f'You managed {counter} squats!')\n",
    "        \n",
    "    # Curl viz\n",
    "    elif user_choice == 2:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(frames, left_angle, '-', color = 'red', label = 'Left Arm Angle')\n",
    "        ax.plot(frames, right_angle, '-', color = 'blue', label = 'Right Arm Angle')\n",
    "        ax.axhline(y=30, color='g', linestyle='--')\n",
    "        ax.legend(loc = 'center left')\n",
    "        ax.set_xlabel('Frames')\n",
    "        ax.set_ylabel('Angle')\n",
    "        print(f'You managed {counter} curls!')\n",
    "        \n",
    "    # Situp viz\n",
    "    else:\n",
    "        plt.plot(frames, body_angles, '-', color = 'red', label = 'Body Angle')\n",
    "        plt.axhline(y=40, color='g', linestyle='--')\n",
    "        plt.xlabel('Frames')\n",
    "        plt.ylabel('Angle')\n",
    "        print(f'You managed {counter} situps!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3d45d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which exercise would you like to do?\n",
      "1. Squat \n",
      "2. Curl \n",
      "3. Sit-up\n",
      "2\n",
      "\n",
      "You managed 0 curls!\n",
      "The red/blue lines show the angle of your targetted body part throughout your exercise, whereas the green dotted line is the minimum angle required for the exercise to be recorded as one repetition.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialise variables\n",
    "counter = 0\n",
    "state = 'Down'\n",
    "range_flag = True\n",
    "halfway = False\n",
    "feedback = ''\n",
    "frame_count = 0\n",
    "# Plotting variables\n",
    "frames = []\n",
    "left_angle = []\n",
    "right_angle = []\n",
    "body_angles = []\n",
    "\n",
    "# Prompt user input for exercise selection\n",
    "while True:\n",
    "    try:\n",
    "        user_choice = int(input('Which exercise would you like to do?\\n1. Squat \\n2. Curl \\n3. Sit-up\\n'))\n",
    "        print(\"\")\n",
    "        if user_choice in [1, 2, 3]:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Please enter either integer 1, 2 or 3\")\n",
    "            print(\"\")\n",
    "    except:\n",
    "        print(\"Please enter either integer 1, 2 or 3\")\n",
    "        print(\"\")\n",
    "\n",
    "# Open webcam\n",
    "feed = cv2.VideoCapture(0)\n",
    "\n",
    "# Get user's maximum resolution\n",
    "WIDTH = 10000\n",
    "HEIGHT = 10000\n",
    "feed.set(cv2.CAP_PROP_FRAME_WIDTH, WIDTH)\n",
    "feed.set(cv2.CAP_PROP_FRAME_HEIGHT, HEIGHT)\n",
    "width = int(feed.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(feed.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Mediapipe Pose model instance\n",
    "with mp_pose.Pose(min_detection_confidence=50, min_tracking_confidence=50) as pose:\n",
    "    while feed.isOpened():\n",
    "        ret, frame = feed.read()\n",
    "        frame_count += 1\n",
    "        frames.append(frame_count)\n",
    "        # Mirror frame\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        # Recolor image from BGR to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Pose detection\n",
    "        detection = pose.process(image)\n",
    "        # Recolor image from RGB back to BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, detection.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "        \n",
    "        # Recognise particular exercise based on user input\n",
    "        if user_choice == 1:\n",
    "            recognise_squat(detection)\n",
    "        elif user_choice == 2:\n",
    "            recognise_curl(detection)\n",
    "        else:\n",
    "            recognise_situp(detection)\n",
    "        \n",
    "\n",
    "        # Status box setup\n",
    "        cv2.rectangle(image, (0,0), (width, int(height*0.1)), (245,117,16), -1)\n",
    "        cv2.putText(image, \"REPS:\", (int(width*0.01), int(height*0.025)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA) # font, size, color, line width, line type\n",
    "        \n",
    "        cv2.putText(image, \"STATE:\", (int(width*0.1), int(height*0.025)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(image, \"FEEDBACK:\", (int(width*0.2), int(height*0.025)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(image, str(counter), (int(width*0.01), int(height*0.08)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(image, state, (int(width*0.1), int(height*0.08)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(image, feedback, (int(width*0.2), int(height*0.08)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        window_name = 'Exercise Counter'\n",
    "        \n",
    "        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(window_name, image)\n",
    "        \n",
    "        # quit webcam\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "feed.release()\n",
    "\n",
    "plot_viz(user_choice)\n",
    "print('The red/blue lines show the angle of your targetted body part throughout your exercise, whereas the green dotted line is the minimum angle required for the exercise to be recorded as one repetition.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d57a395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4253a12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.12.0-py2.py3-none-any.whl (9.1 MB)\n",
      "     ------------------                       4.2/9.1 MB 19.2 kB/s eta 0:04:15\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\Lenova\\anaconda3\\lib\\http\\client.py\", line 462, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\Lenova\\anaconda3\\lib\\http\\client.py\", line 506, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\Lenova\\anaconda3\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\Lenova\\anaconda3\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\Lenova\\anaconda3\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 169, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 248, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\commands\\install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 92, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 546, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 397, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 173, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 156, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 206, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 293, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 225, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 304, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 516, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 587, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 166, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 107, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\network\\download.py\", line 147, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 587, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\Lenova\\anaconda3\\lib\\contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\Users\\Lenova\\AppData\\Roaming\\Python\\Python39\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 455, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)\", ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1650c817",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1110f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b9be908",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rescale_frame(frame, percent=50):\n",
    "    width = int(frame.shape[1] * percent/ 100)\n",
    "    height = int(frame.shape[0] * percent/ 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fafa498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Curl counter variables\n",
    "counter = 0 \n",
    "stage = None\n",
    "\n",
    "\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            \n",
    "            # Get coordinates\n",
    "            hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            \n",
    "           \n",
    "            \n",
    "            # Calculate angle\n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "            \n",
    "            angle_knee = calculate_angle(hip, knee, ankle) #Knee joint angle\n",
    "            \n",
    "            angle_hip = calculate_angle(shoulder, hip, knee)\n",
    "            hip_angle = 180-angle_hip\n",
    "            knee_angle = 180-angle_knee\n",
    "            \n",
    "            # Visualize angle\n",
    "            \"\"\"cv2.putText(image, str(angle), \n",
    "                           tuple(np.multiply(elbow, [640, 480]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\"\"\"\n",
    "            \"\"\"        \n",
    "                \n",
    "            cv2.putText(image, str(angle_knee), \n",
    "                           tuple(np.multiply(knee, [640, 480]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (79, 121, 66), 2, cv2.LINE_AA\n",
    "                                )\"\"\"\n",
    "            \n",
    "            \"\"\"cv2.putText(image, str(angle_hip), \n",
    "                           tuple(np.multiply(hip, [640, 480]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\"\"\"\n",
    "            \n",
    "            # Curl counter logic\n",
    "            if angle_knee > 169:\n",
    "                stage = \"DOWN\"\n",
    "            if angle_knee <= 90 and stage =='DOWN':\n",
    "                stage=\"UP\"\n",
    "                counter +=1\n",
    "                print(counter)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Render squat counter\n",
    "        # Setup status box\n",
    "        cv2.rectangle(image, (0,0), (225,73), (245,117,16), -1)\n",
    "        \n",
    "        # Rep data\n",
    "        cv2.putText(image, 'REPS', (15,12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, str(counter), \n",
    "                    (10,60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Stage data\n",
    "        cv2.putText(image, 'STAGE', (65,12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, stage, \n",
    "                    (60,60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        \n",
    "        cv2.imshow('Squat', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    #out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532c7066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playsound\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py): started\n",
      "  Building wheel for playsound (setup.py): finished with status 'done'\n",
      "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7035 sha256=39d457ea2b96fa17d4df88e5ebaddc04b906f59a388e1269917e9b302d87e78d\n",
      "  Stored in directory: c:\\users\\lenova\\appdata\\local\\pip\\cache\\wheels\\ba\\39\\54\\c8f7ff9a88a644d3c58b4dec802d90b79a2e0fb2a6b884bf82\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install playsound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d2d93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open welcome1.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close welcome1.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: welcome1.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open welcome3.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close welcome3.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: welcome3.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open welcome5.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close welcome5.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: welcome5.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open welcome7.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close welcome7.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: welcome7.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 259 for command:\n",
      "        play welcome10.mp3 wait\n",
      "    The driver cannot recognize the specified command parameter.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close welcome10.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: welcome10.mp3\n",
      "\n",
      "    Error 259 for command:\n",
      "        play welcome11.mp3 wait\n",
      "    The driver cannot recognize the specified command parameter.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close welcome11.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: welcome11.mp3\n",
      "\n",
      "    Error 263 for command:\n",
      "        open welcome12.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close welcome12.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: welcome12.mp3\n",
      "\n",
      "    Error 263 for command:\n",
      "        open welcome13.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close welcome13.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: welcome13.mp3\n",
      "\n",
      "    Error 263 for command:\n",
      "        open welcome14.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close welcome14.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: welcome14.mp3\n",
      "\n",
      "    Error 263 for command:\n",
      "        open welcome15.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close welcome15.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: welcome15.mp3\n",
      "\n",
      "    Error 259 for command:\n",
      "        play welcome16.mp3 wait\n",
      "    The driver cannot recognize the specified command parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n",
      "not visible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open welcome1.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close welcome1.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: welcome1.mp3\n",
      "\n",
      "    Error 263 for command:\n",
      "        open welcome2.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close welcome2.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: welcome2.mp3\n",
      "\n",
      "    Error 263 for command:\n",
      "        open welcome1.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close welcome1.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: welcome1.mp3\n",
      "\n",
      "    Error 263 for command:\n",
      "        open welcome2.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close welcome2.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: welcome2.mp3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from gtts import gTTS\n",
    "from playsound import  playsound\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def checkHandInBox(handX, handY, tlX, tlY, brX, brY):\n",
    "    if handX>tlX and handX<brX and handY>tlY and handY<brY:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def createMenu():\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    curlTlx=220;curlBrx=400;curlTly=100;curlBry=160\n",
    "    deadliftTlx=220;deadliftBrx=400;deadliftTly=200;deadliftBry=260\n",
    "    squatTlx=220;squatBrx=400;squatTly=300;squatBry=360\n",
    "\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "        \n",
    "            # Make detection\n",
    "            results = pose.process(image)\n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                \n",
    "                # Get coordinates\n",
    "\n",
    "                leftHand = [landmarks[mp_pose.PoseLandmark.LEFT_INDEX.value].x,landmarks[mp_pose.PoseLandmark.LEFT_PINKY.value].y]\n",
    "                rightHand = [landmarks[mp_pose.PoseLandmark.RIGHT_INDEX.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_PINKY.value].y]\n",
    "\n",
    "                if(checkHandInBox(leftHand[0]*640,leftHand[1]*480 ,curlTlx, curlTly, curlBrx, curlBry) or checkHandInBox(rightHand[0]*640,rightHand[1]*480 ,curlTlx, curlTly, curlBrx, curlBry)):\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    curl()\n",
    "                    break\n",
    "\n",
    "                if(checkHandInBox(leftHand[0]*640,leftHand[1]*480 ,deadliftTlx, deadliftTly, deadliftBrx, deadliftBry) or checkHandInBox(rightHand[0]*640,rightHand[1]*480 ,deadliftTlx, deadliftTly, deadliftBrx, deadliftBry)):\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    deadlift()\n",
    "                    break\n",
    "\n",
    "                if(checkHandInBox(leftHand[0]*640,leftHand[1]*480 ,squatTlx, squatTly, squatBrx, squatBry) or checkHandInBox(rightHand[0]*640,rightHand[1]*480 ,squatTlx, squatTly, squatBrx, squatBry)):\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    squat()\n",
    "                    break\n",
    "                        \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # curlTlx=220;curlBrx=400;curlTly=200;curlBry=260\n",
    "            cv2.rectangle(image, (curlTlx,curlTly), (curlBrx,curlBry), (245,117,16), -1)\n",
    "            cv2.putText(image, 'BICEP CURL', (220,160), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1, cv2.LINE_AA)\n",
    "            # deadliftTlx=220;deadliftBrx=400;deadliftTly=300;deadliftBry=360\n",
    "            cv2.rectangle(image, (deadliftTlx,deadliftTly), (deadliftBrx,deadliftBry), (245,117,16), -1)\n",
    "            cv2.putText(image, 'DEADLIFT', (220,260), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1, cv2.LINE_AA)\n",
    "            # squatTlx=220;squatBrx=400;squatTly=400;squatBry=460\n",
    "            cv2.rectangle(image, (squatTlx,squatTly), (squatBrx,squatBry), (245,117,16), -1)\n",
    "            cv2.putText(image, 'SQUAT', (220,360), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                    )  \n",
    "            cv2.imshow('Mediapipe Feed', image)\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle \n",
    "\n",
    "\n",
    "def curl():\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Curl counter variables\n",
    "    counter = 0 \n",
    "    stage = None\n",
    "\n",
    "    ## Setup mediapipe instance\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "        \n",
    "            # Make detection\n",
    "            results = pose.process(image)\n",
    "        \n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Extract landmarks\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                \n",
    "                # Get coordinates\n",
    "                shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "                wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "                leftHand = [landmarks[mp_pose.PoseLandmark.LEFT_INDEX.value].x,landmarks[mp_pose.PoseLandmark.LEFT_PINKY.value].y]\n",
    "                rightHand = [landmarks[mp_pose.PoseLandmark.RIGHT_INDEX.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_PINKY.value].y]\n",
    "\n",
    "                if(checkHandInBox(leftHand[0]*640,leftHand[1]*480 ,590,20,670,80) or checkHandInBox(rightHand[0]*640,rightHand[1]*480,600,0,680,60)):\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    createMenu()\n",
    "                    break\n",
    "                \n",
    "                # Calculate angle\n",
    "                angle = calculate_angle(shoulder, elbow, wrist)\n",
    "                \n",
    "                # Visualize angle\n",
    "                cv2.putText(image, str(angle), \n",
    "                            tuple(np.multiply(elbow, [640, 480]).astype(int)), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                    )\n",
    "                \n",
    "                # Curl counter logic\n",
    "                if angle > 160:\n",
    "                    stage = \"down\"\n",
    "                if angle < 30 and stage =='down':\n",
    "                    stage=\"up\"\n",
    "                    counter +=1\n",
    "                    mytext=str(counter)\n",
    "                    language='en'\n",
    "                    myobj=gTTS(text=mytext,lang=language,slow=True)\n",
    "                    # myobj.save(\"welcome1.mp3\")\n",
    "                    # playsound(\"welcome1.mp3\")\n",
    "                    myobj.save(\"welcome\"+str(counter)+\".mp3\")\n",
    "                    playsound(\"welcome\"+str(counter)+\".mp3\")\n",
    "                    print(counter)\n",
    "                        \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Render curl counter\n",
    "            # Setup status box\n",
    "            cv2.rectangle(image, (0,0), (240,73), (245,117,16), -1)\n",
    "            cv2.rectangle(image, (590,20), (670,80), (245,117,16), -1)\n",
    "            cv2.putText(image, 'S', (590,79), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            # Rep data\n",
    "            cv2.putText(image, 'REPS', (15,12), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(counter), \n",
    "                        (10,60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "            # cv2.putText(image, 'CURL', \n",
    "            #             (480,60), \n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Stage data\n",
    "            cv2.putText(image, 'STAGE', (85,12), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, stage, \n",
    "                        (80,60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            \n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                    )               \n",
    "            \n",
    "            cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def checkDeadlift(a,b,c,d,checkUp=False):\n",
    "    if c.visibility>0.5 and d.visibility>0.5:\n",
    "        print(\"visible\")\n",
    "        if checkUp==True:\n",
    "            if a.y<c.y and b.y<d.y:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            if a.y>c.y and b.y>d.y:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "    else:\n",
    "        print(\"not visible\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def deadlift():\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Deadlift counter variables\n",
    "    counter = 0 \n",
    "    stage = None\n",
    "\n",
    "    ## Setup mediapipe instance\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "        \n",
    "            # Make detection\n",
    "            results = pose.process(image)\n",
    "        \n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Extract landmarks\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "                # left_hand = landmarks[mp_pose.PoseLandmark.LEFT_INDEX.value]\n",
    "                # right_hand = landmarks[mp_pose.PoseLandmark.RIGHT_INDEX.value]\n",
    "                # left_knee = landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value]\n",
    "                # right_knee = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value]\n",
    "\n",
    "                leftHand = [landmarks[mp_pose.PoseLandmark.LEFT_INDEX.value].x,landmarks[mp_pose.PoseLandmark.LEFT_PINKY.value].y]\n",
    "                rightHand = [landmarks[mp_pose.PoseLandmark.RIGHT_INDEX.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_PINKY.value].y]\n",
    "\n",
    "                if(checkHandInBox(leftHand[0]*640,leftHand[1]*480 ,590,20,670,80) or checkHandInBox(rightHand[0]*640,rightHand[1]*480,600,0,680,60)):\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    createMenu()\n",
    "                    break\n",
    "\n",
    "                left_hand = landmarks[mp_pose.PoseLandmark.LEFT_INDEX.value]\n",
    "                right_hand = landmarks[mp_pose.PoseLandmark.RIGHT_INDEX.value]\n",
    "                left_knee = landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value]\n",
    "                right_knee = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value]\n",
    "\n",
    "                if checkDeadlift(left_hand,right_hand,left_knee,right_knee):\n",
    "                    stage = \"down\"\n",
    "                if stage==\"down\" and checkDeadlift(left_hand,right_hand,left_knee,right_knee,checkUp=True):\n",
    "                    stage=\"up\"\n",
    "                    counter+=1\n",
    "                    mytext=str(counter)\n",
    "                    language='en'\n",
    "                    myobj=gTTS(text=mytext,lang=language,slow=True)\n",
    "                    myobj.save(\"welcome\"+str(counter)+\".mp3\")\n",
    "                    playsound(\"welcome\"+str(counter)+\".mp3\")\n",
    "                    print(counter)\n",
    "                        \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Setup status box\n",
    "            cv2.rectangle(image, (0,0), (240,73), (245,117,16), -1)\n",
    "            cv2.rectangle(image, (590,20), (670,80), (245,117,16), -1)\n",
    "            cv2.putText(image, 'S', (590,79), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            # Rep data\n",
    "            cv2.putText(image, 'REPS', (15,12), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(counter), \n",
    "                        (10,60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "            # cv2.putText(image, 'DEADLIFT', \n",
    "            #             (460,60), \n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Stage data\n",
    "            cv2.putText(image, 'STAGE', (85,12), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, stage, \n",
    "                        (80,60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            \n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                    )               \n",
    "            \n",
    "            cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "def checkSquat(a,b,c,d,checkUp=False):\n",
    "    if a.visibilty>0.4 and b.visibility>0.4 and c.visibility>0.4 and d.visibility>0.4:\n",
    "        print(\"visible\")\n",
    "        # Cup20=c.y+c.y*0.2\n",
    "        Cdown30=c.y-c.y*0.6\n",
    "        # Dup20=d.y+d.y*0.2\n",
    "        Ddown30=d.y-d.y*0.6\n",
    "        if checkUp==True:\n",
    "            if a.y<Cdown30 and b.y<Ddown30:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            if a.y>Cdown30 and b.y>Ddown30:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "    else:\n",
    "        print(\"not visible\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def squat():\n",
    "    cv2.destroyAllWindows()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Deadlift counter variables\n",
    "    counter = 0 \n",
    "    stage = \"None\"\n",
    "\n",
    "    ## Setup mediapipe instance\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "        \n",
    "            # Make detection\n",
    "            results = pose.process(image)\n",
    "        \n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Extract landmarks\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "                left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "                right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value]\n",
    "                left_knee = landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value]\n",
    "                right_knee = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value]\n",
    "\n",
    "                leftHand = [landmarks[mp_pose.PoseLandmark.LEFT_INDEX.value].x,landmarks[mp_pose.PoseLandmark.LEFT_PINKY.value].y]\n",
    "                rightHand = [landmarks[mp_pose.PoseLandmark.RIGHT_INDEX.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_PINKY.value].y]\n",
    "\n",
    "                if(checkHandInBox(leftHand[0]*640,leftHand[1]*480 ,590,20,670,80) or checkHandInBox(rightHand[0]*640,rightHand[1]*480,600,0,680,60)):\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    createMenu()\n",
    "                    break\n",
    "\n",
    "                if checkSquat(left_hip,right_hip,left_knee,right_knee):\n",
    "                    stage = \"down\"\n",
    "                if stage==\"down\" and checkSquat(left_hip,right_hip,left_knee,right_knee,checkUp=True):\n",
    "                    stage=\"up\"\n",
    "                    counter+=1\n",
    "                    mytext=str(counter)\n",
    "                    language='en'\n",
    "                    myobj=gTTS(text=mytext,lang=language,slow=True)\n",
    "                    myobj.save(\"welcome\"+str(counter)+\".mp3\")\n",
    "                    playsound(\"welcome\"+str(counter)+\".mp3\")\n",
    "                    print(counter)\n",
    "                        \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Setup status box\n",
    "            cv2.rectangle(image, (0,0), (240,73), (245,117,16), -1)\n",
    "            cv2.rectangle(image, (590,20), (670,80), (245,117,16), -1)\n",
    "            cv2.putText(image, 'S', (590,79), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            # Rep data\n",
    "            cv2.putText(image, 'REPS', (15,12), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(counter), \n",
    "                        (10,60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Stage data\n",
    "            cv2.putText(image, 'STAGE', (85,12), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, stage, \n",
    "                        (80,60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "            # cv2.putText(image, 'SQUAT', \n",
    "            #             (470,60), \n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            \n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                    )               \n",
    "            \n",
    "            cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "createMenu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e9fc7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which exercise would you like to do?\n",
      "1. Squat \n",
      "2. Curl \n",
      "3. Sit-up\n",
      "2\n",
      "\n",
      "You managed 0 curls!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# draw landmarks & connections to screen\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# import Pose model\n",
    "mp_pose = mp.solutions.pose\n",
    "def calc_angle(x, y, z):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    z = np.array(z)\n",
    "\n",
    "    radians = np.arctan2(z[1]-y[1], z[0]-y[0]) - np.arctan2(x[1]-y[1], x[0]-y[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle\n",
    "def recognise_curl(detection):\n",
    "    \n",
    "    global counter\n",
    "    global state\n",
    "    global feedback\n",
    "    global range_flag\n",
    "    global left_angle\n",
    "    global right_angle\n",
    "    \n",
    "    try:\n",
    "        landmarks = detection.pose_landmarks.landmark\n",
    "        \n",
    "        # left arm\n",
    "        left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "        left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "        left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y] \n",
    "\n",
    "        # right arm\n",
    "        right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "        right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "        right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "        \n",
    "        left_elbow_angle = calc_angle(left_shoulder, left_elbow, left_wrist)\n",
    "        right_elbow_angle = calc_angle(right_shoulder, right_elbow, right_wrist)\n",
    "        left_angle.append(int(left_elbow_angle))\n",
    "        right_angle.append(int(right_elbow_angle))\n",
    "        \n",
    "        # down state\n",
    "        if left_elbow_angle > 160 and right_elbow_angle > 160:\n",
    "            if not range_flag:\n",
    "                feedback = 'Did not curl completely.'\n",
    "            else:\n",
    "                feedback = 'Good rep!'\n",
    "            state = 'Down'\n",
    "            \n",
    "        # not fully curled\n",
    "        elif (left_elbow_angle > 50 and right_elbow_angle > 50) and state == 'Down':\n",
    "            range_flag = False\n",
    "            feedback = ''\n",
    "            \n",
    "        # up state\n",
    "        elif (left_elbow_angle < 30 and right_elbow_angle < 30) and state == 'Down':\n",
    "            state = 'Up'\n",
    "            feedback = ''\n",
    "            range_flag = True\n",
    "            counter += 1\n",
    "    \n",
    "    except:\n",
    "        left_angle.append(180)\n",
    "        right_angle.append(180)\n",
    "def recognise_squat(detection):\n",
    "    \n",
    "    global counter\n",
    "    global state\n",
    "    global feedback\n",
    "    global left_angle\n",
    "    global right_angle\n",
    "       \n",
    "    try:\n",
    "        landmarks = detection.pose_landmarks.landmark\n",
    "        \n",
    "        # GET COORDINATES\n",
    "        left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "        left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "        left_heel = [landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y]\n",
    "        \n",
    "        right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "        right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "        right_heel = [landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HEEL.value].y]\n",
    "        \n",
    "        left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "        right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "\n",
    "        left = calc_angle(left_hip, left_knee, left_heel)\n",
    "        right = calc_angle(right_hip, right_knee, right_heel)        \n",
    "        left_angle.append(int(left))\n",
    "        right_angle.append(int(right))\n",
    "        \n",
    "        #POSE CHECKING 1: Knees bending inwards    \n",
    "        shoulder_dist = left_shoulder[0] - right_shoulder[0]\n",
    "        knee_dist = left_knee[0] - right_knee[0]\n",
    "\n",
    "        if shoulder_dist - knee_dist > 0.04:\n",
    "            feedback = 'Open up your knees further apart to shoulder width!'\n",
    "        else:\n",
    "            feedback = ''\n",
    "\n",
    "        # standing up\n",
    "        if left > 170 and right > 170:\n",
    "            state = \"Up\"\n",
    "            \n",
    "        if left < 165 and right < 165:\n",
    "            feedback = 'Almost there... lower until height of hips!'\n",
    "            \n",
    "        if left < 140 and right < 140 and state == \"Up\":\n",
    "            state = \"Down\"\n",
    "            counter += 1\n",
    "            \n",
    "        if state == \"Down\":\n",
    "            feedback = 'Good rep!'\n",
    "    \n",
    "    except:\n",
    "        left_angle.append(180)\n",
    "        right_angle.append(180)\n",
    "def recognise_situp(detection):\n",
    "    \n",
    "    global counter\n",
    "    global state\n",
    "    global feedback\n",
    "    global range_flag\n",
    "    global halfway\n",
    "    global body_angles\n",
    "    \n",
    "    try: \n",
    "        landmarks = detection.pose_landmarks.landmark\n",
    "        \n",
    "        left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "        left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "        left_heel = [landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HEEL.value].y]\n",
    "        left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "\n",
    "        # CALCULATE ANGLES \n",
    "        angle_knee = calc_angle(left_hip, left_knee, left_heel)\n",
    "        angle_body = calc_angle(left_shoulder, left_hip, left_knee)\n",
    "        body_angles.append(int(angle_body))\n",
    "      \n",
    "        if (angle_body < 80 and angle_body > 50) and state == \"Down\": #Half-way there (Used for checking bad situps)\n",
    "            halfway = True\n",
    "\n",
    "        if angle_body < 40 and state == \"Down\": #Complete situp\n",
    "            state = \"Up\"\n",
    "            range_flag = True\n",
    "            \n",
    "        if angle_body > 90 and angle_knee < 60: #Resting position;to check if situp was done properly\n",
    "            state = \"Down\"\n",
    "            \n",
    "            if halfway: #Check if a rep was attempted\n",
    "                if range_flag: #Check if a proper rep was performed\n",
    "                    counter += 1\n",
    "                    feedback = \"Good repetition!\"\n",
    "                else:\n",
    "                    feedback = \"Did not perform sit up completely.\"\n",
    "                range_flag = False #Reset vars\n",
    "                halfway = False\n",
    "                \n",
    "        if angle_knee > 70: #Triggers anytime the legs are not tucked in\n",
    "            feedback = \"Keep legs tucked in closer\"\n",
    "\n",
    "    except: \n",
    "        body_angles.append(180)\n",
    "def plot_viz(user_choice):\n",
    "    \n",
    "    # Set figure size\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "    \n",
    "    # Squat viz\n",
    "    if user_choice == 1:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(frames, left_angle, '-', color = 'red', label = 'Left Knee Angle')\n",
    "        ax.plot(frames, right_angle, '-', color = 'blue', label = 'Right Knee Angle')\n",
    "        ax.axhline(y=140, color='g', linestyle='--')\n",
    "        ax.legend(loc = 'center left')\n",
    "        ax.set_xlabel('Frames')\n",
    "        ax.set_ylabel('Angle')\n",
    "        print(f'You managed {counter} squats!')\n",
    "        \n",
    "    # Curl viz\n",
    "    elif user_choice == 2:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(frames, left_angle, '-', color = 'red', label = 'Left Arm Angle')\n",
    "        ax.plot(frames, right_angle, '-', color = 'blue', label = 'Right Arm Angle')\n",
    "        ax.axhline(y=30, color='g', linestyle='--')\n",
    "        ax.legend(loc = 'center left')\n",
    "        ax.set_xlabel('Frames')\n",
    "        ax.set_ylabel('Angle')\n",
    "        print(f'You managed {counter} curls!')\n",
    "        \n",
    "    # Situp viz\n",
    "    else:\n",
    "        plt.plot(frames, body_angles, '-', color = 'red', label = 'Body Angle')\n",
    "        plt.axhline(y=40, color='g', linestyle='--')\n",
    "        plt.xlabel('Frames')\n",
    "        plt.ylabel('Angle')\n",
    "        print(f'You managed {counter} situps!')\n",
    "# initialise variables\n",
    "counter = 0\n",
    "state = 'Down'\n",
    "range_flag = True\n",
    "halfway = False\n",
    "feedback = ''\n",
    "frame_count = 0\n",
    "# Plotting variables\n",
    "frames = []\n",
    "left_angle = []\n",
    "right_angle = []\n",
    "body_angles = []\n",
    "\n",
    "# Prompt user input for exercise selection\n",
    "while True:\n",
    "    try:\n",
    "        user_choice = int(input('Which exercise would you like to do?\\n1. Squat \\n2. Curl \\n3. Sit-up\\n'))\n",
    "        print(\"\")\n",
    "        if user_choice in [1, 2, 3]:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Please enter either integer 1, 2 or 3\")\n",
    "            print(\"\")\n",
    "    except:\n",
    "        print(\"Please enter either integer 1, 2 or 3\")\n",
    "        print(\"\")\n",
    "\n",
    "# Open webcam\n",
    "feed = cv2.VideoCapture(0)\n",
    "\n",
    "# Get user's maximum resolution\n",
    "WIDTH = 10000\n",
    "HEIGHT = 10000\n",
    "feed.set(cv2.CAP_PROP_FRAME_WIDTH, WIDTH)\n",
    "feed.set(cv2.CAP_PROP_FRAME_HEIGHT, HEIGHT)\n",
    "width = int(feed.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(feed.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Mediapipe Pose model instance\n",
    "with mp_pose.Pose(min_detection_confidence=50, min_tracking_confidence=50) as pose:\n",
    "    while feed.isOpened():\n",
    "        ret, frame = feed.read()\n",
    "        frame_count += 1\n",
    "        frames.append(frame_count)\n",
    "        # Mirror frame\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        # Recolor image from BGR to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Pose detection\n",
    "        detection = pose.process(image)\n",
    "        # Recolor image from RGB back to BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, detection.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "        \n",
    "        # Recognise particular exercise based on user input\n",
    "        if user_choice == 1:\n",
    "            recognise_squat(detection)\n",
    "        elif user_choice == 2:\n",
    "            recognise_curl(detection)\n",
    "        else:\n",
    "            recognise_situp(detection)\n",
    "        \n",
    "\n",
    "        # Status box setup\n",
    "        cv2.rectangle(image, (0,0), (width, int(height*0.1)), (245,117,16), -1)\n",
    "        cv2.putText(image, \"REPS:\", (int(width*0.01), int(height*0.025)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA) # font, size, color, line width, line type\n",
    "        \n",
    "        cv2.putText(image, \"STATE:\", (int(width*0.1), int(height*0.025)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(image, \"FEEDBACK:\", (int(width*0.2), int(height*0.025)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(image, str(counter), (int(width*0.01), int(height*0.08)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(image, state, (int(width*0.1), int(height*0.08)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.putText(image, feedback, (int(width*0.2), int(height*0.08)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        window_name = 'Exercise Counter'\n",
    "        \n",
    "        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(window_name, image)\n",
    "        \n",
    "        # quit webcam\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "feed.release()\n",
    "\n",
    "plot_viz(user_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca23ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyttsx3\n",
      "  Downloading pyttsx3-2.90-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: comtypes in c:\\users\\lenova\\anaconda3\\lib\\site-packages (from pyttsx3) (1.1.10)\n",
      "Collecting pypiwin32 (from pyttsx3)\n",
      "  Downloading pypiwin32-223-py3-none-any.whl (1.7 kB)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\lenova\\appdata\\roaming\\python\\python39\\site-packages (from pyttsx3) (303)\n",
      "Installing collected packages: pypiwin32, pyttsx3\n",
      "Successfully installed pypiwin32-223 pyttsx3-2.90\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyttsx3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fe64b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8515987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement threading (from versions: none)\n",
      "ERROR: No matching distribution found for threading\n"
     ]
    }
   ],
   "source": [
    "pip install threading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf483300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
